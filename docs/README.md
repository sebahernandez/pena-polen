# DocumentaciÃ³n - PeÃ±a Polen

Esta carpeta contiene toda la documentaciÃ³n del proyecto PeÃ±a Polen, organizada por temas para facilitar la comprensiÃ³n de la arquitectura y funcionamiento del sistema.

## ğŸ“š Ãndice de DocumentaciÃ³n

### ğŸ—ï¸ [ARCHITECTURE.md](./ARCHITECTURE.md) **[NUEVO]**
DocumentaciÃ³n detallada de la arquitectura del proyecto.
- VisiÃ³n general del sistema
- DescripciÃ³n de capas (Frontend, API, Processing, Data)
- Estructura de componentes
- Flujos de datos principales
- Patrones de diseÃ±o
- Diagrama de data flow
DocumentaciÃ³n completa de todos los endpoints de la API REST del proyecto.
- Endpoints disponibles
- MÃ©todos HTTP soportados
- ParÃ¡metros de request/response
- Ejemplos de uso

### ğŸ”„ [SCRAPING_MANUAL.md](./SCRAPING_MANUAL.md)
Manual para ejecutar el scraping de datos de polen desde polenes.cl.
- Comandos para ejecutar scraping
- ConfiguraciÃ³n de Supabase
- Opciones de automatizaciÃ³n
- Funciones disponibles
- Sistema de notificaciones

### ğŸš€ [VERCEL_DEPLOYMENT.md](./VERCEL_DEPLOYMENT.md)
GuÃ­a para ejecutar scraping manualmente vÃ­a API.
- Ruta API /api/scrape
- Ejemplos con cURL, Postman, JavaScript, Python
- Alternativas de automatizaciÃ³n
- IntegraciÃ³n con GitHub Actions, EasyCron, etc.
GuÃ­a para configurar automatizaciÃ³n de tareas mediante cron jobs.
- ConfiguraciÃ³n de Vercel Cron Functions
- GitHub Actions workflow
- Cron job en servidor
- Monitoreo y alertas

### ğŸ§ª [TESTING_GUIDE.md](./TESTING_GUIDE.md)
GuÃ­a completa para testing del proyecto.
- Unit tests
- Integration tests
- End-to-end tests
- Mejores prÃ¡cticas

### ğŸ”€ [HYBRID_SCRAPING.md](./HYBRID_SCRAPING.md) **[NUEVO]**
ExplicaciÃ³n de la estrategia de scraping hÃ­brida.
- Dual-mode scraping (fetch vs Puppeteer)
- OptimizaciÃ³n para Vercel Serverless
- Razones por las que Puppeteer no funciona en Vercel
- Alternativas de scraping
- Recomendaciones de producciÃ³n

## ğŸ—ï¸ Estructura del Proyecto

```
pena-polen/
â”œâ”€â”€ docs/                          # ğŸ“ DocumentaciÃ³n (esta carpeta)
â”‚   â”œâ”€â”€ README.md                  # Ãndice de documentaciÃ³n
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # Arquitectura del proyecto
â”‚   â”œâ”€â”€ VERCEL_DEPLOYMENT.md       # EjecuciÃ³n vÃ­a API
â”‚   â”œâ”€â”€ API_ENDPOINTS.md           # Endpoints API
â”‚   â”œâ”€â”€ SCRAPING_MANUAL.md         # Manual de scraping
â”‚   â”œâ”€â”€ CRON_SETUP.md              # ConfiguraciÃ³n de automatizaciÃ³n
â”‚   â””â”€â”€ TESTING_GUIDE.md           # GuÃ­a de testing
â”œâ”€â”€ src/                           # CÃ³digo fuente
â”‚   â”œâ”€â”€ components/                # Componentes Astro/React
â”‚   â”œâ”€â”€ lib/                       # Funciones utilitarias
â”‚   â”œâ”€â”€ pages/                     # Rutas de la aplicaciÃ³n
â”‚   â”œâ”€â”€ types/                     # Definiciones TypeScript
â”‚   â””â”€â”€ styles/                    # Estilos CSS
â”œâ”€â”€ public/                        # Archivos estÃ¡ticos
â”œâ”€â”€ package.json                   # Dependencias
â”œâ”€â”€ tsconfig.json                  # ConfiguraciÃ³n TypeScript
â”œâ”€â”€ astro.config.mjs               # ConfiguraciÃ³n Astro
â”œâ”€â”€ tailwind.config.mjs            # ConfiguraciÃ³n Tailwind
â”œâ”€â”€ supabase-schema.sql            # Schema de base de datos
â””â”€â”€ README.md                      # README principal del proyecto
```

## ğŸš€ GuÃ­a RÃ¡pida

### Iniciar desarrollo
```bash
npm run dev
```

### Ejecutar scraping
```bash
npm run scrape:save
```

### Ejecutar tests
```bash
npm run test
```

### Build para producciÃ³n
```bash
npm run build
```

## ğŸ”— InformaciÃ³n Relacionada

- **README Principal**: Ver [/README.md](../README.md) para informaciÃ³n general del proyecto
- **Schema Base de Datos**: Ver [supabase-schema.sql](../supabase-schema.sql) para la estructura de la base de datos
- **ConfiguraciÃ³n**: Revisar archivos de configuraciÃ³n en la raÃ­z (`astro.config.mjs`, `tailwind.config.mjs`, `tsconfig.json`)

## ğŸ“ Notas Importantes

- Todas las variables de entorno deben estar configuradas en `.env` o `.env.local`
- La informaciÃ³n de polen se obtiene de [polenes.cl](https://www.polenes.cl) mediante scraping
- Los datos se almacenan en Supabase y se actualizan periÃ³dicamente
- El sistema incluye notificaciones en tiempo real cuando hay nuevos datos

## ğŸ¤ Contribuir

Para contribuir al proyecto:
1. Revisar la documentaciÃ³n relevante en esta carpeta
2. Seguir las guÃ­as de testing (TESTING_GUIDE.md)
3. Consultar los endpoints disponibles (API_ENDPOINTS.md)
4. Configurar correctamente el scraping (SCRAPING_MANUAL.md)

---

*Ãšltima actualizaciÃ³n: 15 de noviembre de 2025*
